{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlWXLzxbq4RZHrMJOsbtKK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorbahlangene/Fastai-Docs/blob/main/Model_hooks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nbdev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmxx9O0lGsYa",
        "outputId": "b818111c-0e6f-49a2-a1f6-a7ab0de55d4e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nbdev\n",
            "  Downloading nbdev-2.3.12-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m61.4/64.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastcore>=1.5.27 in /usr/local/lib/python3.10/dist-packages (from nbdev) (1.5.29)\n",
            "Collecting execnb>=0.1.4 (from nbdev)\n",
            "  Downloading execnb-0.1.5-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.10/dist-packages (from nbdev) (1.6.3)\n",
            "Collecting ghapi>=1.0.3 (from nbdev)\n",
            "  Downloading ghapi-1.0.4-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.7/58.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchdog (from nbdev)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asttokens (from nbdev)\n",
            "  Downloading asttokens-2.4.0-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from nbdev) (6.0.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from execnb>=0.1.4->nbdev) (7.34.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastcore>=1.5.27->nbdev) (23.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastcore>=1.5.27->nbdev) (23.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from asttokens->nbdev) (1.16.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse->nbdev) (0.41.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->execnb>=0.1.4->nbdev) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->execnb>=0.1.4->nbdev)\n",
            "  Downloading jedi-0.19.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->execnb>=0.1.4->nbdev) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->execnb>=0.1.4->nbdev) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->execnb>=0.1.4->nbdev) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->execnb>=0.1.4->nbdev) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->execnb>=0.1.4->nbdev) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->execnb>=0.1.4->nbdev) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->execnb>=0.1.4->nbdev) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->execnb>=0.1.4->nbdev) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->execnb>=0.1.4->nbdev) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->execnb>=0.1.4->nbdev) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->execnb>=0.1.4->nbdev) (0.2.6)\n",
            "Installing collected packages: watchdog, jedi, asttokens, ghapi, execnb, nbdev\n",
            "Successfully installed asttokens-2.4.0 execnb-0.1.5 ghapi-1.0.4 jedi-0.19.0 nbdev-2.3.12 watchdog-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c05iodTF0oC1",
        "outputId": "7b8f6057-950d-4431-a442-d6542b8b4d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uqq fastbook"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model hooks\n",
        "Callback and helper function to add hooks in models"
      ],
      "metadata": {
        "id": "5mLy7m_o062T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.test_utils import *"
      ],
      "metadata": {
        "id": "tPMSS8kf3PRy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What are hooks"
      ],
      "metadata": {
        "id": "CtZ2cLc23IxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "Q7C4CJw03iRh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forward hooks are functions that take three arguments: **the layer it’s applied to, the input of that layer and the output of that layer**."
      ],
      "metadata": {
        "id": "lbhJAWtU6641"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tst_model = nn.Linear(5,3)\n",
        "\n",
        "def example_forward_hook(m,i,o): print(m,i,o)\n",
        "\n",
        "x = torch.randn(4,5)\n",
        "hook = tst_model.register_forward_hook(example_forward_hook)\n",
        "y = tst_model(x)\n",
        "hook.remove()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwdLjTQ0079k",
        "outputId": "7c8a5c40-9c97-495c-e5d9-5c5e4eff367a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=5, out_features=3, bias=True) (tensor([[-0.1960, -0.7425,  0.4338,  1.1581, -0.7060],\n",
            "        [-1.0166,  0.6263,  0.5599,  0.4935, -0.4149],\n",
            "        [ 0.4090,  0.3788,  0.9381,  0.5656,  0.0719],\n",
            "        [ 0.3580, -0.1364, -0.1676,  0.9226, -0.9239]]),) tensor([[-0.8899, -0.4858, -0.5871],\n",
            "        [-0.2556,  0.0226, -0.4437],\n",
            "        [ 0.0087, -0.0489, -1.1091],\n",
            "        [-0.8057, -0.2550, -0.6010]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tst_model = nn.Linear(5,3)\n",
        "\n",
        "def example_forward_hook(m,i,o): print(m)\n",
        "\n",
        "x = torch.randn(4,5)\n",
        "hook = tst_model.register_forward_hook(example_forward_hook)\n",
        "y = tst_model(x)\n",
        "hook.remove()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78RrVn077C3s",
        "outputId": "48fa3fb6-2a52-493f-e733-c1e3b0faa746"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=5, out_features=3, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tst_model = nn.Linear(5,3)\n",
        "\n",
        "def example_forward_hook(m,i,o): print(i,i[0].shape)\n",
        "\n",
        "x = torch.randn(4,5)\n",
        "hook = tst_model.register_forward_hook(example_forward_hook)\n",
        "y = tst_model(x)\n",
        "hook.remove()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnqf8pXU7C0S",
        "outputId": "8e4861e0-1ae6-4818-ac41-ecd100c2ff4e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[ 0.5443, -0.9213,  2.4496,  0.9330, -0.3271],\n",
            "        [-1.1699,  2.0541, -0.1535,  0.8731,  0.7136],\n",
            "        [-1.1722,  1.5937, -0.2732,  0.5370, -0.1316],\n",
            "        [ 2.4264, -0.3225,  0.8017, -0.7404, -1.4495]]),) torch.Size([4, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tst_model = nn.Linear(5,3)\n",
        "\n",
        "def example_forward_hook(m,i,o): print(o)\n",
        "\n",
        "x = torch.randn(4,5)\n",
        "hook = tst_model.register_forward_hook(example_forward_hook)\n",
        "y = tst_model(x)\n",
        "hook.remove()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtxqC8Us7Cwi",
        "outputId": "ff4706cd-c82c-4157-8072-af24a698dbcd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2836, -0.1895,  0.9892],\n",
            "        [ 0.2430,  0.1717, -0.3140],\n",
            "        [ 0.0885, -0.0724, -0.6834],\n",
            "        [ 0.3885,  0.9768, -0.3817]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hook method"
      ],
      "metadata": {
        "id": "Yk1ZIIC28IdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fastbook\n",
        "from fastbook import *"
      ],
      "metadata": {
        "id": "0Ve5AXQl9tZL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Hook"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDp6DZEp9ySX",
        "outputId": "450bf4aa-02aa-48a1-95ca-82f54cf9b8bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fastai.callback.hook.Hook"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tst_model = nn.Linear(5,3)\n",
        "hook = Hook(tst_model, lambda m,i,o: print(o))\n",
        "y = tst_model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOjej7PP7CtB",
        "outputId": "688d3970-297b-43b6-e294-115a0bba2639"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6625,  0.7216, -0.5922],\n",
            "        [ 0.2128,  0.0497, -0.5045],\n",
            "        [-0.1155,  0.2259, -0.1747],\n",
            "        [-0.3244, -0.8833, -0.4930]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sas3mwzK7Cn8",
        "outputId": "1cb12dae-1d9d-4189-bec5-4304aa1c52c9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6625,  0.7216, -0.5922],\n",
              "        [ 0.2128,  0.0497, -0.5045],\n",
              "        [-0.1155,  0.2259, -0.1747],\n",
              "        [-0.3244, -0.8833, -0.4930]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tst_model = nn.Linear(5,3)\n",
        "def test2_hook(m,i,o): print(i,o)\n",
        "hook = Hook(tst_model, test2_hook)\n",
        "y = tst_model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7BuG0J8_SGp",
        "outputId": "5f412f49-252c-4e0a-dff6-6b36efe5727a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-0.2400, -1.8547, -0.8561,  0.0544, -0.6039],\n",
            "        [-0.1092,  0.8768, -0.9688, -0.5511, -1.1505],\n",
            "        [-1.3190,  1.2971,  0.7561, -0.0980, -0.3736],\n",
            "        [-1.7620,  0.8441, -1.2029,  0.2453,  2.0300]]),) tensor([[ 0.1963,  0.7703,  0.5106],\n",
            "        [ 0.6347,  0.0916, -0.6947],\n",
            "        [ 0.4149, -1.0374, -0.1387],\n",
            "        [ 0.4048, -1.2948, -0.0490]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hooks"
      ],
      "metadata": {
        "id": "1TWJKQIXAj4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Hooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCTSipAGArc9",
        "outputId": "a1f498d7-2b33-41a0-d8d0-165e6334d00b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fastai.callback.hook.Hooks"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create several hooks on the modules in ms with hook_func."
      ],
      "metadata": {
        "id": "_IgBNQulA9ZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [nn.Linear(5,10), nn.ReLU(), nn.Linear(10,3)]\n",
        "tst_model = nn.Sequential(*layers)\n",
        "hooks = Hooks(tst_model, lambda m,i,o: print(o[0].shape))\n",
        "y = tst_model(x)\n",
        "hooks.remove()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjGLcq_qA8_y",
        "outputId": "2e23a33e-0f65-4e21-f7ea-ee0830d7a5f9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10])\n",
            "torch.Size([10])\n",
            "torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEoBj1w6ArI1",
        "outputId": "d5d61788-280b-41df-e2d7-67b1de62a7a3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai.callback.hook.Hooks at 0x7e37ca2932e0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hooks.stored"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4efxiBCCfsI",
        "outputId": "12bc7821-90b8-400d-cd8b-328ee76d293b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [None,None,None]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layers[0](x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BulDb4xACfjr",
        "outputId": "ce334711-86e9-4184-bcc1-0ba2d5c8efe3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5531, -0.8771, -0.3780,  0.3950, -0.2589, -0.1010,  0.6401, -0.0268, -0.5655, -0.3721],\n",
              "        [ 0.4572, -0.4736,  0.2558, -0.7852, -0.1241,  0.2211, -0.0637,  1.6697, -0.2269,  0.1502],\n",
              "        [ 0.6385,  0.4062, -0.0986,  0.1149,  0.1831,  0.3724, -0.8923,  0.5607,  0.4784,  0.3475],\n",
              "        [ 0.5885, -0.7887, -1.8518,  0.1175, -0.6030,  0.5700,  0.4612,  0.0295, -0.2116,  0.5673]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [nn.Linear(5,10), nn.ReLU(), nn.Linear(10,3)]\n",
        "tst_model = nn.Sequential(*layers)\n",
        "hooks = Hooks(tst_model, lambda m,i,o: o)\n",
        "y = tst_model(x)\n",
        "test_eq(hooks.stored[0], layers[0](x))\n",
        "test_eq(hooks.stored[1], F.relu(layers[0](x)))\n",
        "test_eq(hooks.stored[2], y)\n",
        "hooks.remove()"
      ],
      "metadata": {
        "id": "2kTgYpyTCfan"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [nn.Linear(5,10), nn.ReLU(), nn.Linear(10,3)]\n",
        "tst_model = nn.Sequential(*layers)\n",
        "hooks = Hooks(tst_model, lambda m,i,o: print(o))\n",
        "y = tst_model(x)\n",
        "print(\"\\n\")\n",
        "print(hooks.stored[0])\n",
        "\n",
        "hooks.remove()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AD3DdkxCfFV",
        "outputId": "e0838472-58fb-4502-c32d-026878b3654f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.6852,  1.0306, -0.5184,  1.1874,  0.3606,  0.2654,  0.6110, -0.7365,  0.1323,  0.5231],\n",
            "        [ 0.0975,  0.2875,  0.4452,  0.1526,  0.0053,  0.1568,  0.1449, -0.1921, -0.6417,  0.3963],\n",
            "        [-0.0627, -0.7076,  0.7955, -0.4060, -0.5042,  0.0779, -0.0853,  0.5074, -0.6921, -0.5346],\n",
            "        [ 1.8567,  0.9030,  0.0993,  0.2727, -0.9985, -1.3063,  0.7712, -0.5689, -1.0713, -0.7483]])\n",
            "tensor([[0.6852, 1.0306, 0.0000, 1.1874, 0.3606, 0.2654, 0.6110, 0.0000, 0.1323, 0.5231],\n",
            "        [0.0975, 0.2875, 0.4452, 0.1526, 0.0053, 0.1568, 0.1449, 0.0000, 0.0000, 0.3963],\n",
            "        [0.0000, 0.0000, 0.7955, 0.0000, 0.0000, 0.0779, 0.0000, 0.5074, 0.0000, 0.0000],\n",
            "        [1.8567, 0.9030, 0.0993, 0.2727, 0.0000, 0.0000, 0.7712, 0.0000, 0.0000, 0.0000]])\n",
            "tensor([[-0.5224, -0.7714,  0.4092],\n",
            "        [-0.3680, -0.0118,  0.2262],\n",
            "        [-0.3818,  0.1652,  0.1150],\n",
            "        [-0.3017, -0.7995, -0.0766]])\n",
            "\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [nn.Linear(5,10), nn.ReLU(), nn.Linear(10,3)]\n",
        "tst_model = nn.Sequential(*layers)\n",
        "hooks = Hooks(tst_model, lambda m,i,o: o)\n",
        "y = tst_model(x)\n",
        "print(\"\\n\")\n",
        "print(hooks.stored[0])\n",
        "\n",
        "hooks.remove()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8RBzKb3Ce3d",
        "outputId": "0fbc82aa-a8b6-47a1-ea73-4c5ab1458a78"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "tensor([[-0.9226,  0.2338,  0.7396, -0.4916,  0.0244,  1.0041, -0.3825, -0.7541, -0.8064,  0.4093],\n",
            "        [-0.1471, -0.0801,  0.1770, -0.1136, -0.0418,  1.1746,  0.9130, -0.0155, -0.1300, -0.3831],\n",
            "        [ 0.6381,  0.7126, -0.5211, -1.0238,  0.5759,  0.3246,  0.9597,  0.2932,  0.0763, -0.8201],\n",
            "        [-0.2140, -0.3583,  0.2565, -0.1135,  0.1397, -0.1719,  1.4508, -1.5187,  0.9513,  0.6423]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hooks.stored"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbiG6xryHuD4",
        "outputId": "15789c82-e0bd-41b1-8237-00bd95bdb15e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [tensor([[-0.9226,  0.2338,  0.7396, -0.4916,  0.0244,  1.0041, -0.3825, -0.7541, -0.8064,  0.4093],\n",
              "        [-0.1471, -0.0801,  0.1770, -0.1136, -0.0418,  1.1746,  0.9130, -0.0155, -0.1300, -0.3831],\n",
              "        [ 0.6381,  0.7126, -0.5211, -1.0238,  0.5759,  0.3246,  0.9597,  0.2932,  0.0763, -0.8201],\n",
              "        [-0.2140, -0.3583,  0.2565, -0.1135,  0.1397, -0.1719,  1.4508, -1.5187,  0.9513,  0.6423]]),tensor([[0.0000, 0.2338, 0.7396, 0.0000, 0.0244, 1.0041, 0.0000, 0.0000, 0.0000, 0.4093],\n",
              "        [0.0000, 0.0000, 0.1770, 0.0000, 0.0000, 1.1746, 0.9130, 0.0000, 0.0000, 0.0000],\n",
              "        [0.6381, 0.7126, 0.0000, 0.0000, 0.5759, 0.3246, 0.9597, 0.2932, 0.0763, 0.0000],\n",
              "        [0.0000, 0.0000, 0.2565, 0.0000, 0.1397, 0.0000, 1.4508, 0.0000, 0.9513, 0.6423]]),tensor([[ 0.0614, -0.4749, -0.3101],\n",
              "        [-0.2112, -0.5151, -0.0540],\n",
              "        [-0.6004, -0.4172, -0.3468],\n",
              "        [-0.3489, -0.3165,  0.1106]])]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HookCallback"
      ],
      "metadata": {
        "id": "huSEKSvV-RhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        " HookCallback (modules=None, every=None, remove_end=True, is_forward=True,\n",
        "               detach=True, cpu=True, include_paramless=False, hook=None)\n",
        "```"
      ],
      "metadata": {
        "id": "0wh_P_JDEcfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "synth_learner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FIKkifh_l1s",
        "outputId": "6b0ff076-542b-43db-bcfb-40b3cdf94aa2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function fastai.test_utils.synth_learner(n_trn=10, n_val=2, cuda=False, lr=0.001, data=None, model=None, *, loss_func: 'callable | None' = None, opt_func: 'Optimizer | OptimWrapper' = <function Adam at 0x7e37cca0b760>, splitter: 'callable' = <function trainable_params at 0x7e37cfc50e50>, cbs: 'Callback | MutableSequence | None' = None, metrics: 'callable | MutableSequence | None' = None, path: 'str | Path | None' = None, model_dir: 'str | Path' = 'models', wd: 'float | int | None' = None, wd_bn_bias: 'bool' = False, train_bn: 'bool' = True, moms: 'tuple' = (0.95, 0.85, 0.95), default_cbs: 'bool' = True)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TstCallback(HookCallback):\n",
        "  def hook(self, m,i,o): return o\n",
        "  def after_batch(self): test_eq(self.hooks.stored[0], self.pred)\n",
        "\n",
        "learn = synth_learner(n_trn=5, cbs = TstCallback())\n",
        "learn.fit(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "xnQBOwk77Ck1",
        "outputId": "38a73348-cfc0-495d-b0e4-aea3b4e9685f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fastai/callback/core.py:69: UserWarning: You are shadowing an attribute (modules) that exists in the learner. Use `self.learn.modules` to avoid this\n",
            "  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>32.211258</td>\n",
              "      <td>24.315292</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TstCallback(HookCallback):\n",
        "    def __init__(self, modules=None, remove_end=True, detach=True, cpu=False):\n",
        "        super().__init__(modules, None, remove_end, False, detach, cpu)\n",
        "    def hook(self, m, i, o): return o\n",
        "    def after_batch(self):\n",
        "        if self.training:\n",
        "            test_eq(self.hooks.stored[0][0], 2*(self.pred-self.y)/self.pred.shape[0])\n",
        "\n",
        "learn = synth_learner(n_trn=5, cbs = TstCallback())\n",
        "learn.fit(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "8VtjlpU77CdD",
        "outputId": "7c4f32fb-628b-463d-c46f-c52a6cf206ea"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>10.517303</td>\n",
              "      <td>8.470366</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1344: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc(synth_learner)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "KwyJ-Bj4EXU2",
        "outputId": "df72f625-f15d-4417-8692-a748e842c69d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<hr/>\n",
              "<h3>synth_learner</h3>\n",
              "<blockquote><pre><code>synth_learner(n_trn=10, n_val=2, cuda=False, lr=0.001, data=None, model=None, loss_func:callable|None=None, opt_func:Optimizer|OptimWrapper=<function Adam>, splitter:callable=<function trainable_params>, cbs:Callback|MutableSequence|None=None, metrics:callable|MutableSequence|None=None, path:str|Path|None=None, model_dir:str|Path='models', wd:float|int|None=None, wd_bn_bias:bool=False, train_bn:bool=True, moms:tuple=(0.95, 0.85, 0.95), default_cbs:bool=True)</code></pre></blockquote>\n",
              "<p><a href=\"https://docs.fast.ai/test_utils.html#synth_learner\" target=\"_blank\" rel=\"noreferrer noopener\">Show in docs</a></p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class TstCallback(HookCallback):\n",
        "#     def __init__(self, modules=None, remove_end=True, detach=True, cpu=False):\n",
        "#         super().__init__(modules, None, remove_end, False, detach, cpu)\n",
        "#     def hook(self, m, i, o): return o\n",
        "#     def after_batch(self):\n",
        "#         if self.training:\n",
        "#             test_eq(self.hooks.stored[0][0], 2*(self.pred-self.y)/self.pred.shape[0])\n",
        "\n",
        "# layers = [nn.Linear(5,10), nn.ReLU(), nn.Linear(10,3)]\n",
        "# tst_model = nn.Sequential(*layers)\n",
        "\n",
        "# learn = synth_learner(n_trn=5, model=tst_model, cbs = TstCallback())\n",
        "# learn.fit(1)"
      ],
      "metadata": {
        "id": "ALPkIqsOEXIt"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "using a dataset"
      ],
      "metadata": {
        "id": "Co-Z5K_Bmalu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc(ActivationStats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "oQuskEBkmfb0",
        "outputId": "4ede8407-6c7a-47fb-86ea-dfc9843808d2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<hr/>\n",
              "<h3>ActivationStats</h3>\n",
              "<blockquote><pre><code>ActivationStats(with_hist=False, modules=None, every=None, remove_end=True, is_forward=True, detach=True, cpu=True, include_paramless=False, hook=None)</code></pre></blockquote><p>Callback that record the mean and std of activations.</p>\n",
              "<p><a href=\"https://docs.fast.ai/callback.hook.html#activationstats\" target=\"_blank\" rel=\"noreferrer noopener\">Show in docs</a></p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XTYCdokBmfKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vFbS8IzLme5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NN4HGWJPmepW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bqkn2ILomeZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ijeLeIyTEW8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dXi1Rrj-EWwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p0wzZBM7EWa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9d9Z6OVW7CUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fFCJRKo27CJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HHDH9wNH7B7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d95lvyjl3ca4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}